from __future__ import annotations

import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any
from urllib.parse import urlencode

import streamlit as st

from stock_screener.pipelines.daily_batch import DailyBatchPipeline
from stock_screener.storage.db import init_db
from stock_screener.storage.repository import Repository

DB_PATH = Path("data/screener.db")
DB_PATH.parent.mkdir(parents=True, exist_ok=True)
init_db(DB_PATH)
repo = Repository(DB_PATH)
pipeline = DailyBatchPipeline(DB_PATH)

st.set_page_config(layout="wide", page_title="KR Fundamental Screener")
st.title("ğŸ‡°ğŸ‡· í•œêµ­ ì£¼ì‹ Fundamental Screener (pykrx + SQLite cache)")
st.caption("ìµœì´ˆ ì‹¤í–‰ ì‹œ pykrx ìˆ˜ì§‘ìœ¼ë¡œ ì‹œê°„ì´ ê±¸ë¦¬ë©°, ì´í›„ì—ëŠ” DB snapshotì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
st.caption("ê¸°ë³¸ asof = ìµœì‹  ê±°ë˜ì¼(ê°€ê²© ë°ì´í„° ê¸°ì¤€), í•´ë‹¹ ê±°ë˜ì¼ snapshotì´ ì—†ìœ¼ë©´ ì¬ê³„ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.")


@dataclass(frozen=True)
class FilterSpec:
    name: str
    ftype: str
    default: Any


FILTER_SPECS: list[FilterSpec] = [
    FilterSpec("ticker_input", "str", ""),
    FilterSpec("mkt", "list", []),
    FilterSpec("mcap_mode", "str", "any"),
    FilterSpec("mcap_bucket", "str", "any"),
    FilterSpec("mcap_min", "float", 0.0),
    FilterSpec("mcap_max", "float", 0.0),
    FilterSpec("apply_value_min", "bool", False),
    FilterSpec("value_min", "float", 0.0),
    FilterSpec("apply_pbr_max", "bool", False),
    FilterSpec("pbr_max", "float", 1.0),
    FilterSpec("apply_roe_min", "bool", False),
    FilterSpec("roe_min", "float", 0.1),
    FilterSpec("apply_eps_positive", "bool", False),
    FilterSpec("apply_reserve_ratio_min", "bool", False),
    FilterSpec("reserve_ratio_min", "float", 500.0),
    FilterSpec("apply_eps_cagr_5y", "bool", False),
    FilterSpec("eps_cagr_5y_min", "float", 0.15),
    FilterSpec("apply_eps_yoy_q", "bool", False),
    FilterSpec("eps_yoy_q_min", "float", 0.25),
    FilterSpec("above_200ma", "bool", False),
    FilterSpec("apply_near_high", "bool", False),
    FilterSpec("near_high_min", "float", 0.9),
    FilterSpec("sort_col", "str", "mcap"),
    FilterSpec("ascending", "bool", False),
    FilterSpec("limit", "int", 100),
]

MCAP_MODES: dict[str, str] = {
    "any": "Any",
    "bucket": "êµ¬ê°„ì„ íƒ",
    "custom": "Custom",
}

MCAP_BUCKETS: list[dict[str, Any]] = [
    {"key": "any", "label": "ì „ì²´", "min_mcap": None, "max_mcap": None},
    {"key": "mega", "label": "ì´ˆëŒ€í˜•ì£¼ (10ì¡° ì´ìƒ)", "min_mcap": 10_000_000_000_000.0, "max_mcap": None},
    {"key": "large", "label": "ëŒ€í˜•ì£¼ (2ì¡°~10ì¡°)", "min_mcap": 2_000_000_000_000.0, "max_mcap": 10_000_000_000_000.0},
    {"key": "mid", "label": "ì¤‘í˜•ì£¼ (3ì²œì–µ~2ì¡°)", "min_mcap": 300_000_000_000.0, "max_mcap": 2_000_000_000_000.0},
    {"key": "small", "label": "ì†Œí˜•ì£¼ (5ë°±ì–µ~3ì²œì–µ)", "min_mcap": 50_000_000_000.0, "max_mcap": 300_000_000_000.0},
    {"key": "micro", "label": "ì´ˆì†Œí˜•ì£¼ (5ë°±ì–µ ë¯¸ë§Œ)", "min_mcap": None, "max_mcap": 50_000_000_000.0},
]

MCAP_BUCKET_MAP = {bucket["key"]: (bucket["min_mcap"], bucket["max_mcap"]) for bucket in MCAP_BUCKETS}
MCAP_BUCKET_LABEL_MAP = {bucket["key"]: bucket["label"] for bucket in MCAP_BUCKETS}


def _get_query_params() -> dict[str, Any]:
    if hasattr(st, "query_params"):
        return dict(st.query_params)
    return st.experimental_get_query_params()


def _set_query_params(params: dict[str, Any]) -> None:
    if hasattr(st, "query_params"):
        qp = st.query_params
        qp.clear()
        for key, value in params.items():
            qp[key] = value
        return
    st.experimental_set_query_params(**params)


def _parse_bool(raw: Any, *, default: bool) -> bool:
    if raw is None:
        return default
    value = raw[0] if isinstance(raw, list) and raw else raw
    normalized = str(value).strip().lower()
    if normalized in {"1", "true", "t", "yes", "y", "on"}:
        return True
    if normalized in {"0", "false", "f", "no", "n", "off"}:
        return False
    raise ValueError(f"invalid bool: {value}")


def _parse_num(raw: Any, cast_type: type[int] | type[float], *, default: int | float) -> int | float:
    if raw is None:
        return default
    value = raw[0] if isinstance(raw, list) and raw else raw
    try:
        return cast_type(value)
    except (TypeError, ValueError) as exc:
        raise ValueError(f"invalid {cast_type.__name__}: {value}") from exc


def _parse_list(raw: Any, *, default: list[str]) -> list[str]:
    if raw is None:
        return default
    values = raw if isinstance(raw, list) else str(raw).split(",")
    return [item.strip() for item in values if str(item).strip()]


def _parse_str(raw: Any, *, default: str) -> str:
    if raw is None:
        return default
    if isinstance(raw, list):
        return str(raw[0]) if raw else default
    return str(raw)


def _parse_query_filter_value(spec: FilterSpec, query_params: dict[str, Any]) -> Any:
    raw = query_params.get(spec.name)
    if spec.ftype == "bool":
        return _parse_bool(raw, default=spec.default)
    if spec.ftype == "int":
        return _parse_num(raw, int, default=spec.default)
    if spec.ftype == "float":
        return _parse_num(raw, float, default=spec.default)
    if spec.ftype == "list":
        return _parse_list(raw, default=list(spec.default))
    return _parse_str(raw, default=spec.default)


def _serialize_query_filter_value(spec: FilterSpec, value: Any) -> str | list[str] | None:
    if value == spec.default or value in (None, ""):
        return None
    if spec.ftype == "bool":
        return "1" if bool(value) else "0"
    if spec.ftype in {"int", "float", "str"}:
        return str(value)
    if spec.ftype == "list":
        values = [str(item).strip() for item in value if str(item).strip()]
        return values if values else None
    return None


def _run_action_with_progress(action_label: str, callback):
    progress_text = st.empty()
    progress_bar = st.progress(0)
    progress_text.info(f"{action_label}: ìš”ì²­ ì ‘ìˆ˜")
    progress_bar.progress(15)
    progress_text.info(f"{action_label}: ì‘ì—… ì‹¤í–‰ ì¤‘")
    progress_bar.progress(45)
    result = callback()
    progress_text.info(f"{action_label}: ê²°ê³¼ ë°˜ì˜ ì¤‘")
    progress_bar.progress(85)
    progress_bar.progress(100)
    progress_text.success(f"{action_label}: ì™„ë£Œ")
    return result


query_params = _get_query_params()
if "query_params_restored" not in st.session_state:
    st.session_state.query_parse_errors = []
    for spec in FILTER_SPECS:
        try:
            st.session_state[spec.name] = _parse_query_filter_value(spec, query_params)
        except ValueError:
            st.session_state[spec.name] = spec.default
            st.session_state.query_parse_errors.append(spec.name)
    if st.session_state.get("mcap_mode") not in MCAP_MODES:
        st.session_state.mcap_mode = "any"
        st.session_state.query_parse_errors.append("mcap_mode")
    if st.session_state.get("mcap_bucket") not in MCAP_BUCKET_MAP:
        st.session_state.mcap_bucket = "any"
        st.session_state.query_parse_errors.append("mcap_bucket")
    st.session_state.query_params_restored = True

if st.session_state.get("query_parse_errors"):
    st.warning(
        "ì¼ë¶€ URL í•„í„°ê°’ì„ ë³µì›í•˜ì§€ ëª»í•´ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤: "
        + ", ".join(st.session_state.query_parse_errors)
    )

if "asof" not in st.session_state:
    st.session_state.asof = repo.get_latest_price_date() or repo.get_latest_snapshot_date()

latest_price_date = repo.get_latest_price_date()
latest_snapshot_date = repo.get_latest_snapshot_date()
if latest_price_date and latest_price_date != latest_snapshot_date:
    auto_sync_target = latest_price_date
    if st.session_state.get("auto_snapshot_synced_for") != auto_sync_target:
        try:
            with st.spinner(f"ìµœì‹  ê±°ë˜ì¼({auto_sync_target}) snapshot ìë™ ì¬ê³„ì‚° ì¤‘..."):
                auto_result = _run_action_with_progress(
                    "ìµœì‹  ê±°ë˜ì¼ snapshot ìë™ ë™ê¸°í™”",
                    lambda: pipeline.rebuild_snapshot_only(asof_date=auto_sync_target),
                )
            st.session_state.asof = auto_result.asof_date
            st.session_state.auto_snapshot_synced_for = auto_sync_target
            st.success(f"ìµœì‹  ê±°ë˜ì¼ snapshot ìë™ ë™ê¸°í™” ì™„ë£Œ: {auto_result.asof_date}")
        except ValueError as exc:
            st.warning(f"ìµœì‹  ê±°ë˜ì¼ snapshot ìë™ ë™ê¸°í™” ì‹¤íŒ¨: {exc}")

c1, c2, c3 = st.columns([1, 1, 1])
with c1:
    refresh_full = st.button("ì „ì²´ ìˆ˜ì§‘ + ìŠ¤ëƒ…ìƒ·", type="primary")
with c2:
    refresh_snapshot = st.button("ìŠ¤ëƒ…ìƒ·ë§Œ ì¬ê³„ì‚°", help="ì´ë¯¸ ìˆ˜ì§‘ëœ DB ë°ì´í„°ë¡œ snapshotë§Œ ë‹¤ì‹œ ê³„ì‚°")
with c3:
    refresh_reserve = st.button("ìœ ë³´ìœ¨ë§Œ ì—…ë°ì´íŠ¸", help="ë„¤ì´ë²„ í¬ë¡¤ë§ìœ¼ë¡œ ìµœì‹  ìœ ë³´ìœ¨ë§Œ ì—…ë°ì´íŠ¸")

if refresh_full:
    with st.spinner("pykrx ì „ì²´ ìˆ˜ì§‘ + snapshot ìƒì„± ì¤‘... (ì´ˆê¸° 1íšŒ ëŠë¦¼)"):
        result = _run_action_with_progress("ì „ì²´ ìˆ˜ì§‘ + ìŠ¤ëƒ…ìƒ·", lambda: pipeline.run(asof_date=None))
    st.session_state.asof = result.asof_date
    st.success(
        f"ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {result.asof_date} | í‹°ì»¤ {result.tickers}ê°œ | "
        f"prices {result.prices:,}ê±´ | cap {result.cap:,}ê±´ | fundamental {result.fundamental:,}ê±´ | snapshot {result.snapshot:,}ê±´"
    )

if refresh_snapshot:
    try:
        with st.spinner("DB ìºì‹œ ê¸°ë°˜ snapshotë§Œ ì¬ê³„ì‚° ì¤‘..."):
            result = _run_action_with_progress(
                "ìŠ¤ëƒ…ìƒ· ì¬ê³„ì‚°",
                lambda: pipeline.rebuild_snapshot_only(asof_date=repo.get_latest_price_date()),
            )
        st.session_state.asof = result.asof_date
        st.success(f"ìŠ¤ëƒ…ìƒ· ì¬ê³„ì‚° ì™„ë£Œ: {result.asof_date} | snapshot {result.snapshot:,}ê±´")
    except ValueError as exc:
        st.error(f"ìŠ¤ëƒ…ìƒ·ë§Œ ì¬ê³„ì‚° ì‹¤íŒ¨: {exc}")

if refresh_reserve:
    with st.spinner("ë„¤ì´ë²„ í¬ë¡¤ë§ìœ¼ë¡œ ìœ ë³´ìœ¨ ì—…ë°ì´íŠ¸ ì¤‘..."):
        update_result = _run_action_with_progress(
            "ìœ ë³´ìœ¨ ì—…ë°ì´íŠ¸",
            lambda: pipeline.update_reserve_ratio_only(asof_date=repo.get_latest_price_date()),
        )
        updated_asof, updated_rows = update_result
        _run_action_with_progress(
            "ìœ ë³´ìœ¨ ë°˜ì˜ snapshot ì¬ê³„ì‚°",
            lambda: pipeline.rebuild_snapshot_only(asof_date=updated_asof),
        )
    st.session_state.asof = updated_asof
    st.success(f"ìœ ë³´ìœ¨ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_asof} | reserve_ratio {updated_rows:,}ê±´")

asof = st.session_state.asof
if not asof:
    st.warning("snapshotì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ì „ì²´ ìˆ˜ì§‘ + ìŠ¤ëƒ…ìƒ·' ë˜ëŠ” 'ìŠ¤ëƒ…ìƒ·ë§Œ ì¬ê³„ì‚°' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

base = repo.load_snapshot(asof)
if base.empty:
    st.warning(
        "í•´ë‹¹ ê±°ë˜ì¼ ìŠ¤ëƒ…ìƒ·ì´ ì—†ìŠµë‹ˆë‹¤. 'ìŠ¤ëƒ…ìƒ·ë§Œ ì¬ê³„ì‚°' ë²„íŠ¼ìœ¼ë¡œ ìŠ¤ëƒ…ìƒ· ì¬ê³„ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )
    st.stop()

st.subheader(f"Snapshot as of {asof}")
st.write(f"í˜„ì¬ snapshot ì¢…ëª© ìˆ˜: **{len(base):,}ê°œ**")

st.markdown("### ì¡°ê±´ ì„ íƒ")
st.caption("ì›í•˜ëŠ” ì¡°ê±´ë§Œ ì²´í¬í•´ì„œ ì ìš©í•˜ì„¸ìš”. ì²´í¬í•˜ì§€ ì•Šì€ ì¡°ê±´ì€ í•„í„°ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

descriptive_tab, fundamental_tab, technical_tab = st.tabs(["Descriptive", "Fundamental", "Technical"])

with descriptive_tab:
    ticker_input = st.text_input("í‹°ì»¤ ì§ì ‘ ì…ë ¥", help="ì½¤ë§ˆ(,) ë˜ëŠ” ê³µë°±ìœ¼ë¡œ ì—¬ëŸ¬ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", key="ticker_input")

    raw_tickers = [token.strip().upper() for token in re.split(r"[\s,]+", ticker_input or "") if token.strip()]
    ticker_list = list(dict.fromkeys(raw_tickers))

    mkt = st.multiselect("ì‹œì¥", sorted(base["market"].dropna().unique().tolist()), key="mkt")

    mcap_mode = st.radio(
        "ì‹œì´ í•„í„° ëª¨ë“œ",
        options=list(MCAP_MODES.keys()),
        format_func=lambda mode: MCAP_MODES[mode],
        horizontal=True,
        key="mcap_mode",
    )

    mcap_bucket = st.selectbox(
        "ì‹œì´ êµ¬ê°„",
        options=[bucket["key"] for bucket in MCAP_BUCKETS],
        format_func=lambda key: MCAP_BUCKET_LABEL_MAP[key],
        disabled=mcap_mode != "bucket",
        key="mcap_bucket",
    )

    custom_mode = mcap_mode == "custom"
    mcap_min = st.number_input(
        "ìµœì†Œ ì‹œì´(ì›)",
        min_value=0.0,
        step=100_000_000.0,
        disabled=not custom_mode,
        key="mcap_min",
    )
    mcap_max = st.number_input(
        "ìµœëŒ€ ì‹œì´(ì›)",
        min_value=0.0,
        step=100_000_000.0,
        disabled=not custom_mode,
        key="mcap_max",
    )

    apply_value_min = st.checkbox("ìµœì†Œ 20D í‰ê·  ê±°ë˜ëŒ€ê¸ˆ(ì›) ì ìš©", key="apply_value_min")
    value_min = st.number_input(
        "ìµœì†Œ 20D í‰ê·  ê±°ë˜ëŒ€ê¸ˆ(ì›)",
        min_value=0.0,

        step=100_000_000.0,
        disabled=not apply_value_min,
        key="value_min",
    )

with fundamental_tab:
    apply_pbr_max = st.checkbox("ìµœëŒ€ PBR ì ìš©", key="apply_pbr_max")
    pbr_max = st.number_input("ìµœëŒ€ PBR", min_value=0.0, step=0.1, disabled=not apply_pbr_max, key="pbr_max")

    apply_roe_min = st.checkbox("ìµœì†Œ ROE proxy ì ìš©", key="apply_roe_min")
    roe_min = st.number_input("ìµœì†Œ ROE proxy", step=0.01, disabled=not apply_roe_min, key="roe_min")

    apply_eps_positive = st.checkbox("EPS í‘ì ê¸°ì—…ë§Œ(ì ì ì œì™¸)", key="apply_eps_positive")

    apply_reserve_ratio_min = st.checkbox("ìµœì†Œ ìœ ë³´ìœ¨(%) ì ìš©", key="apply_reserve_ratio_min")
    reserve_ratio_min = st.number_input(
        "ìµœì†Œ ìœ ë³´ìœ¨(%)", step=50.0, disabled=not apply_reserve_ratio_min, key="reserve_ratio_min"
    )

    apply_eps_cagr_5y = st.checkbox("ìµœê·¼ 5ë…„ EPS CAGR ì¡°ê±´ ì ìš©", key="apply_eps_cagr_5y")
    eps_cagr_5y_min = st.number_input(
        "ìµœê·¼ 5ë…„ EPS CAGR ìµœì†Œ",

        step=0.01,
        format="%.2f",
        disabled=not apply_eps_cagr_5y,
        key="eps_cagr_5y_min",
    )

    apply_eps_yoy_q = st.checkbox("ìµœê·¼ ë¶„ê¸° EPS YoY ì¡°ê±´ ì ìš©", key="apply_eps_yoy_q")
    eps_yoy_q_min = st.number_input(
        "ìµœê·¼ ë¶„ê¸° EPS YoY ìµœì†Œ",

        step=0.01,
        format="%.2f",
        disabled=not apply_eps_yoy_q,
        key="eps_yoy_q_min",
    )

with technical_tab:
    above_200ma = st.checkbox("200ì¼ì„  ìœ„ ì¡°ê±´ ì ìš©", key="above_200ma")

    apply_near_high = st.checkbox("í˜„ì¬ê°€ / 52ì£¼ ì‹ ê³ ê°€ ì¡°ê±´ ì ìš©", key="apply_near_high")
    near_high_min = st.number_input(
        "í˜„ì¬ê°€ / 52ì£¼ ì‹ ê³ ê°€ ìµœì†Œ",

        step=0.01,
        format="%.2f",
        disabled=not apply_near_high,
        key="near_high_min",
    )


active_filter_count = sum(
    [
        int(bool(ticker_list)),
        int(bool(mkt)),
        int(mcap_mode != "any"),
        int(apply_value_min),
        int(apply_pbr_max),
        int(apply_reserve_ratio_min),
        int(apply_roe_min),
        int(apply_eps_positive),
        int(above_200ma),
        int(apply_eps_cagr_5y),
        int(apply_eps_yoy_q),
        int(apply_near_high),
    ]
)
st.caption(f"ì ìš© ì¤‘ì¸ ì¡°ê±´ ìˆ˜: {active_filter_count}ê°œ")

filtered = base.copy()
missing_tickers: list[str] = []
if ticker_list:
    available_tickers = set(filtered["ticker"].astype(str).str.strip().str.upper())
    missing_tickers = [ticker for ticker in ticker_list if ticker not in available_tickers]
    filtered = filtered[filtered["ticker"].astype(str).str.strip().str.upper().isin(ticker_list)]

if mkt:
    filtered = filtered[filtered["market"].isin(mkt)]
mcap_filter_min: float | None = None
mcap_filter_max: float | None = None
if mcap_mode == "bucket":
    mcap_filter_min, mcap_filter_max = MCAP_BUCKET_MAP[mcap_bucket]
elif mcap_mode == "custom":
    mcap_filter_min = mcap_min if mcap_min > 0 else None
    mcap_filter_max = mcap_max if mcap_max > 0 else None
    if mcap_filter_min is not None and mcap_filter_max is not None and mcap_filter_min >= mcap_filter_max:
        st.warning("Custom ì‹œì´ ë²”ìœ„ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœëŒ€ ì‹œì´ì€ ìµœì†Œ ì‹œì´ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")

if mcap_filter_min is not None:
    filtered = filtered[filtered["mcap"] >= mcap_filter_min]
if mcap_filter_max is not None:
    filtered = filtered[filtered["mcap"] < mcap_filter_max]
if apply_value_min:
    filtered = filtered[filtered["avg_value_20d"] >= value_min]
if apply_pbr_max:
    filtered = filtered[(filtered["pbr"].notna()) & (filtered["pbr"] <= pbr_max)]
if apply_reserve_ratio_min:
    filtered = filtered[(filtered["reserve_ratio"].notna()) & (filtered["reserve_ratio"] >= reserve_ratio_min)]
if apply_roe_min:
    filtered = filtered[(filtered["roe_proxy"].notna()) & (filtered["roe_proxy"] >= roe_min)]
if apply_eps_positive:
    filtered = filtered[filtered["eps_positive"] == 1]
if above_200ma:
    filtered = filtered[filtered["dist_sma200"] >= 0]
if apply_eps_cagr_5y:
    filtered = filtered[(filtered["eps_cagr_5y"].notna()) & (filtered["eps_cagr_5y"] >= eps_cagr_5y_min)]
if apply_eps_yoy_q:
    filtered = filtered[(filtered["eps_yoy_q"].notna()) & (filtered["eps_yoy_q"] >= eps_yoy_q_min)]
if apply_near_high:
    filtered = filtered[(filtered["near_52w_high_ratio"].notna()) & (filtered["near_52w_high_ratio"] >= near_high_min)]

sort_col = st.selectbox(
    "ì •ë ¬ ì»¬ëŸ¼",
    ["mcap", "pbr", "reserve_ratio", "roe_proxy", "ret_3m", "div", "avg_value_20d", "eps_cagr_5y", "eps_yoy_q", "near_52w_high_ratio"],
    key="sort_col",
)
ascending = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ", key="ascending")
limit = st.slider("ì¶œë ¥ ê°œìˆ˜", min_value=10, max_value=500, step=10, key="limit")

query_filter_state: dict[str, Any] = {}
for spec in FILTER_SPECS:
    serialized = _serialize_query_filter_value(spec, st.session_state.get(spec.name, spec.default))
    if serialized is not None:
        query_filter_state[spec.name] = serialized

if mcap_mode != "custom":
    query_filter_state.pop("mcap_min", None)
    query_filter_state.pop("mcap_max", None)
if mcap_mode != "bucket":
    query_filter_state.pop("mcap_bucket", None)

if mcap_mode == "custom":
    query_filter_state["mcap_min"] = str(mcap_min)
    query_filter_state["mcap_max"] = str(mcap_max)

_set_query_params(query_filter_state)

share_query_string = urlencode(query_filter_state, doseq=True)
share_link = f"?{share_query_string}" if share_query_string else ""
st.caption("í•„í„° ìƒíƒœê°€ URLì— ìë™ ë°˜ì˜ë©ë‹ˆë‹¤. ë§í¬ë¥¼ ë³µì‚¬í•´ ë™ì¼í•œ ì¡°ê±´ì„ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
st.code(share_link or "(ê¸°ë³¸ í•„í„° ìƒíƒœ: ê³µìœ í•  ì¶”ê°€ íŒŒë¼ë¯¸í„° ì—†ìŒ)", language="text")
st.button("ê³µìœ  ë§í¬ ë³µì‚¬", disabled=True, help="ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ URLì„ ë³µì‚¬í•´ ê³µìœ í•˜ì„¸ìš”.")

filtered = filtered.sort_values(sort_col, ascending=ascending).head(limit)

if ticker_list:
    st.caption(f"í‹°ì»¤ ì§ì ‘ ì…ë ¥: {len(ticker_list)}ê°œ ì¤‘ {len(ticker_list) - len(missing_tickers)}ê°œ ë§¤ì¹­")
    if missing_tickers:
        st.warning("snapshotì— ì—†ëŠ” í‹°ì»¤: " + ", ".join(missing_tickers))

if filtered.empty:
    st.warning("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. Growth ì¡°ê±´(EPS CAGR/EPS YoY) ì„ê³„ê°’ì„ ë‚®ì¶”ê±°ë‚˜ ì²´í¬ë¥¼ í•´ì œí•´ ë³´ì„¸ìš”.")

show_cols = [
    "ticker", "name", "market", "close", "mcap", "avg_value_20d", "pbr", "reserve_ratio", "per", "div", "dps",
    "eps", "bps", "roe_proxy", "eps_positive", "ret_3m", "ret_1y", "dist_sma200", "pos_52w",
    "near_52w_high_ratio", "eps_cagr_5y", "eps_yoy_q",
]
st.dataframe(filtered[show_cols], width="stretch", hide_index=True)

csv = filtered[show_cols].to_csv(index=False).encode("utf-8-sig")
st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name=f"screener_{asof}.csv", mime="text/csv")
